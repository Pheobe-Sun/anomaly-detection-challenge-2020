{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "# from sklearn.metrics import accuracy_score,confusion_matrix, classification_report, balanced_accuracy_score\n",
    "# from sklearn.metrics import auc,precision_recall_curve\n",
    "# from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, make_scorer\n",
    "f1_scorer = make_scorer(f1_score, average=\"macro\")\n",
    "\n",
    "# from graphviz import Source\n",
    "# from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier,RandomForestClassifier,BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from imblearn.under_sampling import NearMiss\n",
    "# from imblearn.over_sampling import SMOTE,ADASYN\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, window_size):\n",
    "    '''\n",
    "    data_dir (str): Base directory of data \n",
    "    window_size (str): Window size for input examples\n",
    "    window_func (str): Window function reference as defined in utils.preprocess\n",
    "                       Option are either 'window' or 'window_func'\n",
    "    '''\n",
    "    train_dir = os.path.join(data_dir, 'training')\n",
    "    train_str = os.path.join(train_dir, 'training_{}.csv')\n",
    "    test_str = os.path.join(data_dir, 'dataset_{}.csv')\n",
    "\n",
    "    train_xs = []\n",
    "    train_ys = []\n",
    "    for i in [1, 2, 3, 4, 5, 100]: # file name updated to v2\n",
    "        train_df_i = pd.read_csv(train_str.format(str(i)))\n",
    "        \n",
    "    # adding padded values and then windowing\n",
    "        #         train_xi = window_func(train_df_i.kpi_value.values, window_size)\n",
    "        local_min = train_df_i.kpi_value[0:window_size].min() # Using the global min as the padding \n",
    "        pad_min = np.ones(window_size) * local_min\n",
    "        x_padded = np.concatenate([pad_min, train_df_i.kpi_value.values])\n",
    "        train_xi = [x_padded[j:j+window_size] for j in range(len(x_padded)-(window_size))]\n",
    "     \n",
    "        train_xs.append(train_xi)\n",
    "        train_ys.append(train_df_i.anomaly_label.values)\n",
    "    x_train = np.concatenate(train_xs)\n",
    "    y_train = np.concatenate(train_ys)\n",
    "    assert len(x_train) == len(y_train)\n",
    "    \n",
    "    test_xs = []\n",
    "    test_ys = []\n",
    "    for i in [1,2,3,4,5,6,7,8,9,10,11,12,13,100,101,102,103,105,106]:  # file name updated to v2\n",
    "        test_df_i = pd.read_csv(test_str.format(str(i)))\n",
    "#         test_xi = window_func(test_df_i.values[:,1], window_size)\n",
    "        test_local_min = test_df_i.kpi_value.values[0:window_size].min() # Using the local min as the padding \n",
    "        test_pad_min = np.ones(window_size) * test_local_min\n",
    "        test_x_padded = np.concatenate([test_pad_min, train_df_i.kpi_value.values])\n",
    "        test_xi = [test_x_padded[j:j+window_size] for j in range(len(test_x_padded)-(window_size))]\n",
    "\n",
    "    test_xs.append(test_xi)\n",
    "    x_test = np.concatenate(test_xs)\n",
    "    print(\"Train_x shape: {}\\nTrain_y shape: {}\\n\\nTest_x shape: {}\".format(x_train.shape, y_train.shape, x_test.shape))\n",
    "    return x_train, y_train, x_test\n",
    "\n",
    "def window_min_max(x):\n",
    "    x_min = x.min(axis=1).reshape(-1, 1)\n",
    "    x_max = x.max(axis=1).reshape(-1, 1)\n",
    "    for i in range(len(x)):\n",
    "        if x_max[i] > x_min[i]:\n",
    "            x[i] =  (x[i] - x_min[i])/(x_max[i] - x_min[i])\n",
    "        else:  # add scenario where x_max = x_min in a window \n",
    "            x[i] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Pheobe\\\\Documents\\\\[B]Huawei-Challenge-2020\\\\draft'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_x shape: (54337, 100)\n",
      "Train_y shape: (54337,)\n",
      "\n",
      "Test_x shape: (20159, 100)\n"
     ]
    }
   ],
   "source": [
    "data_dir_v2 =\"../for_students/data_v2\"\n",
    "x, y, z = load_data(data_dir_v2, 100) # z is the target_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window level normalisation\n",
    "x = window_min_max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross val incides\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively using Hold-out testing\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN3 - f1-score: 0.58\n",
      "KNN3 - f1-score: 0.85\n",
      "KNN3 - f1-score: 0.68\n",
      "KNN3 - f1-score: 0.63\n",
      "KNN3 - f1-score: 0.66\n"
     ]
    }
   ],
   "source": [
    "# KNN_3\n",
    "kNN_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "kNN_3_scores = cross_val_score(kNN_3, x, y, scoring='f1_macro', cv=skf, n_jobs=-1, error_score='raise')\n",
    "for score in list(kNN_3_scores):\n",
    "    print(\"KNN3 - f1-score: {:.2f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN5 - f1-score: 0.60\n",
      "KNN5 - f1-score: 0.83\n",
      "KNN5 - f1-score: 0.65\n",
      "KNN5 - f1-score: 0.63\n",
      "KNN5 - f1-score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# KNN_5\n",
    "kNN_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "kNN_5_scores = cross_val_score(kNN_5, x, y, scoring='f1_macro', cv=skf, n_jobs=-1, error_score='raise')\n",
    "for score in list(kNN_5_scores):\n",
    "    print(\"KNN5 - f1-score: {:.2f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - f1-score: 0.49\n",
      "Logistic Regression - f1-score: 0.49\n",
      "Logistic Regression - f1-score: 0.49\n",
      "Logistic Regression - f1-score: 0.49\n",
      "Logistic Regression - f1-score: 0.49\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logistic_reg = LogisticRegression(max_iter=4000)\n",
    "lr_scores = cross_val_score(logistic_reg, x, y, scoring='f1_macro', cv=skf, n_jobs=-1, error_score='raise')\n",
    "for score in list(lr_scores):\n",
    "    print(\"Logistic Regression - f1-score: {:.2f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - f1-score: 0.64\n",
      "Gradient Boosting - f1-score: 0.76\n",
      "Gradient Boosting - f1-score: 0.58\n",
      "Gradient Boosting - f1-score: 0.62\n",
      "Gradient Boosting - f1-score: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "grad_boost = GradientBoostingClassifier(max_depth=5)\n",
    "gb_scores = cross_val_score(grad_boost, x, y, scoring='f1_macro', cv=skf, n_jobs=-1, error_score='raise')\n",
    "for score in list(gb_scores):\n",
    "    print(\"Gradient Boosting - f1-score: {:.2f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes - f1-score: 0.30\n",
      "Gaussian Naive Bayes - f1-score: 0.50\n",
      "Gaussian Naive Bayes - f1-score: 0.15\n",
      "Gaussian Naive Bayes - f1-score: 0.14\n",
      "Gaussian Naive Bayes - f1-score: 0.04\n",
      "Bernoulli Naive Bayes - f1-score: 0.27\n",
      "Bernoulli Naive Bayes - f1-score: 0.40\n",
      "Bernoulli Naive Bayes - f1-score: 0.49\n",
      "Bernoulli Naive Bayes - f1-score: 0.49\n",
      "Bernoulli Naive Bayes - f1-score: 0.49\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "gnb = GaussianNB()\n",
    "bnb = BernoulliNB()\n",
    "mnb = MultinomialNB()\n",
    "y_pred = gnb.fit(x_train,y_train).predict(x_test)\n",
    "\n",
    "gnb_scores = cross_val_score(gnb, x, y, scoring='f1_macro', cv=skf, n_jobs=-1, error_score='raise')\n",
    "for score in list(gnb_scores):\n",
    "    print(\"Gaussian Naive Bayes - f1-score: {:.2f}\".format(score))\n",
    "\n",
    "bnb_scores = cross_val_score(bnb, x, y, scoring='f1_macro', cv=skf, n_jobs=-1, error_score='raise')\n",
    "for score in list(bnb_scores):\n",
    "    print(\"Bernoulli Naive Bayes - f1-score: {:.2f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - f1-score: 0.63\n",
      "Random Forest - f1-score: 0.63\n",
      "Random Forest - f1-score: 0.49\n",
      "Random Forest - f1-score: 0.60\n",
      "Random Forest - f1-score: 0.49\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestClassifier()\n",
    "rf_scores = cross_val_score(random_forest, x, y, scoring='f1_macro', cv=skf, n_jobs=-1, error_score='raise')\n",
    "for score in list(rf_scores):\n",
    "    print(\"Random Forest - f1-score: {:.2f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - f1-score: 0.49\n",
      "SVM - f1-score: 0.49\n",
      "SVM - f1-score: 0.49\n",
      "SVM - f1-score: 0.49\n",
      "SVM - f1-score: 0.49\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svc = LinearSVC()\n",
    "svc_scores = cross_val_score(svc, x, y, scoring='f1_macro', cv=skf, n_jobs=-1, error_score='raise')\n",
    "for score in list(svc_scores):\n",
    "    print(\"SVM - f1-score: {:.2f}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
